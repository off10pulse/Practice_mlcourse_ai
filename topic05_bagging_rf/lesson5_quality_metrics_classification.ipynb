{"cells":[{"cell_type":"markdown","metadata":{"id":"qVtRzLXlOljU"},"source":["<center>\n","<img src=\"../../img/ods_stickers.jpg\">\n","## Открытый курс по машинному обучению. Сессия № 2\n","\n","Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."]},{"cell_type":"markdown","metadata":{"id":"QuAeBhGEOljW"},"source":["# <center>Основные метрики качества классификации\n","\n","[Статья](https://habrahabr.ru/company/ods/blog/328372/) на Хабре по этой теме."]},{"cell_type":"markdown","metadata":{"id":"wQp3Eif8OljW"},"source":["### Матрица ошибок\n","Существует множество различных числовых характеристик, позволяющих измерить качество бинарного классификатора. В случае двух классов возможны всего 4 исхода при классификации данного объекта. Их удобно отображать с помощью матрицы ошибок (confusion matrix).Это таблица с двумя строками и двумя столбцами, в ячейках которой указаны следующие значения:\n","- $TP$ = число верно классифицированных положительных примеров\n","- $FP$ = число отрицательных примеров, классифицированных положительно (ошибки первого рода)\n","- $TN$ = число верно классифицированных отрицательных примеров\n","- $FN$ = число положительных примеров, классифицированных отрицательно (ошибки второго рода)\n","\n","<center>\n","<img src=\"../../img/contingency.png\" width = \"500\">\n","</center>\n","\n","Получить такую таблицу можно с помощью функции sklearn.metrics.confusion_matrix, передав ей на вход истинные и предсказанные классификатором метки."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2zgZfgROljX","executionInfo":{"status":"ok","timestamp":1712353671193,"user_tz":-180,"elapsed":1604,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}},"outputId":"3a9df1e4-4578-495b-bfc5-40d0e0831939"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[2, 1],\n","       [3, 2]])"]},"metadata":{},"execution_count":1}],"source":["%matplotlib inline\n","import numpy as np\n","import seaborn as sns\n","from sklearn import metrics\n","\n","true_labels = np.array([0, 1, 0, 0, 1, 1, 1, 1])\n","predicted_labels = np.array([0, 1, 1, 0, 0, 1, 0, 0])\n","\n","M = metrics.confusion_matrix(true_labels, predicted_labels)\n","M"]},{"cell_type":"markdown","metadata":{"id":"cSvJmCQsOljX"},"source":["### Характеристики бинарного классификатора\n","Основываясь на данной таблице, можно ввести несколько величин, характеризующих бинарный классификатор:\n","$$rec = TPR = \\frac{TP}{TP + FN},\\quad SPC = \\frac{TN}{TN + FP},\\quad prec = PPV = \\frac{TP}{TP + FP},\\quad FPR = 1 - SPC,$$\n","\n","$$ACC = \\frac{TP + TN}{TP + TN + FP + FN},\\quad F1 = 2\\frac{PPV\\cdot TRP}{PPV + TPR}.$$\n","\n","Полнота $TPR$ (True positive rate, recall, sensitivity) - доля верно классифицированных положительных примеров среди всех положительных примеров.\n","\n","Специфичность $SPC$ (Specificity, true negative rate) - доля верно классифицированных отрицательных примеров среди всех отрицательных примеров.\n","\n","Точность $PPV$ (Positive predictive value, precision) - доля верно классифицированных положительных примеров среди всех примеров, классифицированных положительно.\n","\n","$FPR$ (False positive rate) - доля ошибочно классифицированных отрицательных примеров среди всех отрицательных примеров.\n","\n","$ACC$ (Accuracy) - доля верно классифицированных примеров среди всех примеров. Основная характеристика качества классификации.\n","\n","$F1$ (F1-measure) - среднее гармоническое точности и полноты. Позволяет учесть обе характеристики одновременно.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gGpft1s-OljY","executionInfo":{"status":"ok","timestamp":1712353740489,"user_tz":-180,"elapsed":338,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}},"outputId":"c3c1131a-12ff-4b70-edd3-ecda13ebf013"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.6666666666666666, 0.4, 0.5, 0.5)"]},"metadata":{},"execution_count":2}],"source":["PPV = metrics.precision_score(true_labels, predicted_labels)\n","TPR = metrics.recall_score(true_labels, predicted_labels)\n","F1 = metrics.f1_score(true_labels, predicted_labels)\n","ACC = metrics.accuracy_score(true_labels, predicted_labels)\n","PPV, TPR, F1, ACC"]},{"cell_type":"markdown","metadata":{"id":"YNbVVxhTOljY"},"source":["### ROC-кривая и AUC\n","\n","Большинство бинарных классификаторов имеют вид $a(x) = \\mbox{sign}(f(x, w) - w_0)$, где $w, w_0$ - параметры алгоритма. То есть сначала строится разделяющая поверхность $f(x, w) = w_0$, после чего объекты, находяющиеся по одну сторону от неё классифицируются положительно, по другую - отрицательно.\n","\n","ROC-кривая (Receiver Operating Characteristic) - это графическая характеристика качества бинарного классификатора, выражающая зависимость TPR от FPR при варьировании порога решающего правила. Она наглядно представляет, каким будет качество классификации при различных значениях $w_0$ и фиксированном значении $w$.\n","\n","ROC-кривая проходит через точки (0, 0) и (1, 1) и монотонно не убывает. Чем ближе кривая внутри квадрата $[0, 1]\\times[0, 1]$ к левому верхнему углу, тем лучше. Идеальный вариант - кривая, проходящая через три точки: (0, 0), (1, 1) и (0, 1). Диагональ данного квадрата соответствует случайному гаданию. Типичная ROC-кривая для классификатора соответствует кривой B на рисунке.\n","<center>\n","<img src=\"../../img/ROC.jpg\" width = \"350\">\n","</center>\n","На практике ROC-кривую всегда оценивают по независимой тестовой выборке, для того чтобы избежать переобучения.\n","\n","Площадь под ROC-кривой AUC (Area Under Curve) является количественной характеристикой качества классификации, не зависящей от соотношения цен ошибок. Чем больше значение AUC, тем «лучше» модель классификации."]},{"cell_type":"markdown","metadata":{"id":"Ii_L9qPQOljY"},"source":["### Случай дисбаланса классов\n","\n","Возможные [действия](http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/):\n","- Собрать больше данных, особенно примеров редкого класса (не всегда возможно)\n","- Использовать методы, основанные на деревьях решений  - случайный лес, градиентный бустинг над деревьями. Деревья не так подвержены проблеме дисбаланса классов\n","- Использовать метрики типа F1, ROC AUC и [Cohen's kappa](https://en.wikipedia.org/wiki/Cohen%27s_kappa), а не accuracy\n","- Использовать метрику, в которой ошибка на объекте из редкого класса входит с большим весом, чем ошибка на объекте из частого класса\n","- Применять [oversampling](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis) и [undersampling](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis). В первом случае в выборку добавляются представители редкого класса (сэмплируются с замещением). Во втором - представители частого класса случайным образом удаляются из выборки\n","- Сгенерировать искусственных представителей редкого класса. [SMOTE](http://www.jair.org/papers/paper953.html) (Synthetic Minority Over-sampling Technique). [Реализация](https://github.com/fmfn/UnbalancedDataset) на Python\n","- Разбить один большой класс на несколько поменьше и применить стратегии One Vs. All или One Vs. One\n","- Применить алгоритмы поиска выбросов или OneClass алгоритмы (например, OneClass SVM)"]},{"cell_type":"markdown","metadata":{"id":"2E8AIWEROljY"},"source":["## Примеры"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"k-qunz8COljY","executionInfo":{"status":"ok","timestamp":1712354000697,"user_tz":-180,"elapsed":341,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}}},"outputs":[],"source":["import sys\n","\n","from sklearn.svm import SVC, LinearSVC\n","\n","if sys.version_info.major == 2:\n","    from urllib import urlopen\n","elif sys.version_info.major == 3:\n","    from urllib.request import urlopen\n","\n","from sklearn import datasets\n","from sklearn.metrics import auc, roc_curve\n","from sklearn.model_selection import cross_val_score, train_test_split\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.neighbors import KNeighborsClassifier"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"ISPvMb-BOljZ","executionInfo":{"status":"error","timestamp":1712354004725,"user_tz":-180,"elapsed":864,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}},"outputId":"f9fa86aa-cc95-41dd-de54-5bf85efc7716"},"outputs":[{"output_type":"error","ename":"HTTPError","evalue":"HTTP Error 404: Not Found","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-26ba075fcb78>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading Pima Indians Diabetes data from UCI Machine learning repository\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"]}],"source":["# Loading Pima Indians Diabetes data from UCI Machine learning repository\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n","raw_data = urlopen(url)\n","data = np.loadtxt(raw_data, delimiter=\",\")\n","\n","X = data[:, :8]\n","y = data[:, 8]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n","C = 10.0  # Regularization parameter of the error term\n","\n","lin_svm = LinearSVC(C=C, dual=False).fit(X_train, y_train)\n","y_score = lin_svm.decision_function(X_test)\n","\n","# Compute ROC curve and ROC area\n","fpr, tpr, _ = roc_curve(y_test, y_score)\n","roc_auc = auc(fpr, tpr)\n","\n","# Plot of a ROC curve for a specific class\n","plt.figure()\n","plt.plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n","plt.plot([0, 1], [0, 1], \"k--\")\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"Receiver operating characteristic example\")\n","plt.legend(loc=\"lower right\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"v7tYgqs_OljZ"},"source":["Указанные выше характеристики можно использовать для подбора параметров алгоритмов, например, с помощью кросс-валидации. Найдём оптимальное с точки зрения F1-меры число ближайших соседей в алгоритме kNN."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p71RT_AMOljZ"},"outputs":[],"source":["knn = KNeighborsClassifier()\n","k_s = np.arange(1, 50, 2)\n","\n","scores_f1 = list()\n","\n","for k in k_s:\n","    knn.n_neighbors = k\n","    scores_f1.append(np.mean(cross_val_score(knn, X, y, scoring=\"f1\")))\n","\n","plt.figure(1, figsize=(10, 5))\n","plt.clf()\n","plt.plot(k_s, scores_f1, linewidth=2)\n","plt.axvline(k_s[np.argmax(scores_f1)], color=\"r\")\n","plt.ylabel(\"F1-score\")\n","plt.xlabel(\"Parameter k\")\n","plt.xlim(1, 49)\n","plt.title(\"F1-optimal number of neighbors, $k$ = %d\" % k_s[np.argmax(scores_f1)])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ZhaTgvc1OljZ"},"source":["### Многоклассовая классификация\n","В случае, когда число классов больше двух, матрица ошибок определяется аналогичным образом: на пересечении $i$-ой строки и $j$-го столбца стоит число примеров $i$-го класса, отнесённых классификатором к классу $j$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRpgvVLZOljZ"},"outputs":[],"source":["true_labels = np.array([0, 1, 2, 0, 1, 2, 0, 1, 2])\n","predicted_labels = np.array([0, 2, 0, 2, 1, 0, 0, 1, 2])\n","\n","M = metrics.confusion_matrix(true_labels, predicted_labels)\n","M"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"xdwgijKmOlja"},"source":["### One vs. All\n","Многоклассовая классификация может быть сведена к бинарной различными способами. Одним из них является подход One vs. All. Его суть в следующем: для каждого класса $i \\in \\{1, \\dots, k\\}$ обучим бинарный классификатор $a_i(x) = \\mbox{sign}f_i(x)$ на исходной выборке с изменёнными метками (объекты $i$-го класса получают метку 1, все оставшиеся объекты - метку 0), то есть мы учим $a_i$ отличать $i$-ый класс от всех остальных. После чего итоговый классификатор строится как $a(x) = \\mbox{argmax}_{i \\in \\{1, \\dots, k\\}} f_i(x)$, то есть он выдаёт класс с наибольшей оценкой $f_i(x)$."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZaIa_JxOlja","executionInfo":{"status":"ok","timestamp":1712354053334,"user_tz":-180,"elapsed":417,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}},"outputId":"13a7452f-5f01-4e8d-fa27-113a8efc90a1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9666666666666667"]},"metadata":{},"execution_count":5}],"source":["iris = datasets.load_iris()\n","X, y = iris.data, iris.target\n","# Fitting One vs. All version of linear SVM\n","onevsall = OneVsRestClassifier(LinearSVC()).fit(X, y)\n","metrics.accuracy_score(y, onevsall.predict(X))"]},{"cell_type":"markdown","metadata":{"id":"KBVc8xiGOlja"},"source":["### Cсылки:\n","\n","- [Статья](http://habrahabr.ru/post/228963/) \"Как заставить работать бинарный классификатор чуточку лучше\" на Habrahabr\n","- [ROC-кривая](http://www.machinelearning.ru/wiki/index.php?title=ROC-%D0%BA%D1%80%D0%B8%D0%B2%D0%B0%D1%8F)\n","- [Характеристики](https://en.wikipedia.org/wiki/Precision_and_recall) бинарного классификатора\n","- [One vs. All и One vs. One](https://en.wikipedia.org/wiki/Multiclass_classification)\n","- [Quora](https://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set) про несбаланированные выборки\n","- про несбаланированные выборки на [ресурсе](http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/) Machine Learning Mastery"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}